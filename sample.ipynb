{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f656307-e777-49c3-af94-8d11b4b7ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "from pnu_learning import PNULearning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5133879e-848c-4d7d-864d-c35334d74b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0b9a54-a743-4fe4-8885-e1ba338abddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f990919-5fff-4548-85ec-1a8f3c8153e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f25b4e8-20c2-4c9c-9546-527f2017228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4fc95f-f110-4382-aa57-0f99680b391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = trainset.data, trainset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a36f082-d65a-4e44-9b8f-adb8c86efc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = testset.data, testset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd38ffbd-c134-4a51-bab2-966bda0351bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = {0, 1}だけのデータで2値分類に\n",
    "x_train = np.array(x_train).astype(np.float32) / 255.\n",
    "y_train = np.array(y_train).reshape(-1)\n",
    "x_train = x_train[y_train<=1]\n",
    "y_train = y_train[y_train<=1]\n",
    "y_train = [-1 if y==0 else 1 for y in y_train]\n",
    "y_train = np.array(y_train).astype(np.int32)\n",
    "x_test = np.array(x_test).astype(np.float32) / 255.\n",
    "y_test = np.array(y_test).reshape(-1)\n",
    "x_test = x_test[y_test<=1]\n",
    "y_test = y_test[y_test<=1]\n",
    "y_test = [-1 if y==0 else 1 for y in y_test]\n",
    "y_test = np.array(y_test).astype(np.int32)\n",
    "\n",
    "n_train = len(y_train)                  \n",
    "negative, positive = np.unique(y_train)\n",
    "n_p = (y_train == positive).sum() \n",
    "prior = float(n_p) / float(n_train)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "n_labeled = 100\n",
    "n_unlabeled = n_train - n_labeled \n",
    "\n",
    "n_p_labeled = int(prior * n_labeled)\n",
    "n_n_labeled = n_labeled - n_p_labeled\n",
    "\n",
    "np.random.seed(seed=46)\n",
    "#ランダムに入れ替えて、先頭からn_labeledのデータのみラベルを残す\n",
    "perm = np.random.permutation(n_train)\n",
    "x_train = x_train[perm]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "x_p_labeled = x_train[y_train == positive][:n_p_labeled]\n",
    "x_n_labeled = x_train[y_train == negative][:n_n_labeled]\n",
    "\n",
    "x_p_unlabeled = x_train[y_train == positive][n_p_labeled:]\n",
    "x_n_unlabeled = x_train[y_train == negative][n_n_labeled:]\n",
    "\n",
    "x_train = np.concatenate((x_p_labeled, x_n_labeled, x_p_unlabeled, x_n_unlabeled), axis=0)\n",
    "y_train = np.concatenate((np.ones(n_p_labeled), -np.ones(n_n_labeled), np.zeros(n_unlabeled)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac4a626-2247-4200-853e-ed61e59f3273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.convv1 = nn.Conv2d(3, 96, 3, padding=\"same\")\n",
    "        self.batchnorm2d1 = nn.BatchNorm2d(96)\n",
    "        self.convv2 = nn.Conv2d(96, 192, 3, padding=\"same\")\n",
    "        self.batchnorm2d2 = nn.BatchNorm2d(192)\n",
    "        self.convv3 = nn.Conv2d(192, 192, 3, padding=\"same\")\n",
    "        self.batchnorm2d3 = nn.BatchNorm2d(192)\n",
    "        self.convv4 = nn.Conv2d(192, 10, 1, padding=\"same\")\n",
    "        self.batchnorm2d4 = nn.BatchNorm2d(10)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(10*input_shape[-1]*input_shape[-1], 512)\n",
    "        self.batchnorm1d1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.batchnorm1d2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.is_cuda)\n",
    "        x = self.convv1(x)\n",
    "        x = self.batchnorm2d1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.convv2(x)\n",
    "        x = self.batchnorm2d2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.convv3(x)\n",
    "        x = self.batchnorm2d3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.convv4(x)\n",
    "        x = self.batchnorm2d4(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1d1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.batchnorm1d2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "139b89b0-5995-4c02-a819-5792f1bb4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [3, 32, 32]\n",
    "model = CNNModel(input_shape)\n",
    "loss_func = torch.sigmoid\n",
    "optimizer = optim.Adam\n",
    "lr = 1e-5\n",
    "n_epoch = 10\n",
    "batch_size = 1000\n",
    "\n",
    "p_ratio = 0.5\n",
    "eta = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a6e197-22b9-402b-9a30-542c3504afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "789f22f6-3d75-4ec1-aac6-f9f5c3a908ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = PNULearning(model=model, loss_func=loss_func, optimizer=optimizer, lr=lr, p_ratio=p_ratio, eta=eta, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fdbc0-996c-44b1-bda4-2b0ceb19e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10\n",
      "loss: 0.5458, acc: 0.3036, precision: 0.1250, recall: 0.2000\n",
      "loss: 0.5113, acc: 0.4881, precision: 0.4167, recall: 0.4111\n",
      "loss: 0.5019, acc: 0.5223, precision: 0.4554, recall: 0.5583\n",
      "loss: 0.4988, acc: 0.5054, precision: 0.4310, recall: 0.6067\n",
      "loss: 0.4906, acc: 0.5402, precision: 0.4925, recall: 0.6389\n",
      "loss: 0.4903, acc: 0.5523, precision: 0.4935, recall: 0.6429\n",
      "loss: 0.4886, acc: 0.5628, precision: 0.5256, recall: 0.6562\n",
      "loss: 0.4846, acc: 0.5767, precision: 0.5450, recall: 0.6698\n",
      "loss: 0.4720, acc: 0.5790, precision: 0.5238, recall: 0.7028\n",
      "test_loss: 0.3965, test_acc: 0.5000, test_precision: 0.5000, test_recall: 1.0000\n",
      "epoch: 2/10\n",
      "loss: 0.3268, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.3268, acc: 0.9259, precision: 0.8889, recall: 1.0000\n",
      "loss: 0.3182, acc: 0.9444, precision: 0.9167, recall: 1.0000\n",
      "loss: 0.3165, acc: 0.9556, precision: 0.9333, recall: 1.0000\n",
      "loss: 0.3224, acc: 0.9352, precision: 0.9236, recall: 0.9792\n",
      "loss: 0.3141, acc: 0.9335, precision: 0.8988, recall: 0.9821\n",
      "loss: 0.3214, acc: 0.9293, precision: 0.8976, recall: 0.9844\n",
      "loss: 0.3098, acc: 0.9260, precision: 0.8904, recall: 0.9861\n",
      "loss: 0.3085, acc: 0.9243, precision: 0.8847, recall: 0.9875\n",
      "test_loss: 0.3905, test_acc: 0.5225, test_precision: 0.5115, test_recall: 0.9970\n",
      "epoch: 3/10\n",
      "loss: 0.2207, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.2195, acc: 0.9710, precision: 0.9333, recall: 1.0000\n",
      "loss: 0.2421, acc: 0.9470, precision: 0.8875, recall: 1.0000\n",
      "loss: 0.2385, acc: 0.9576, precision: 0.9100, recall: 1.0000\n",
      "loss: 0.2499, acc: 0.9647, precision: 0.9250, recall: 1.0000\n",
      "loss: 0.2493, acc: 0.9538, precision: 0.9153, recall: 1.0000\n",
      "loss: 0.2472, acc: 0.9596, precision: 0.9259, recall: 1.0000\n",
      "loss: 0.2450, acc: 0.9641, precision: 0.9341, recall: 1.0000\n",
      "loss: 0.2394, acc: 0.9677, precision: 0.9407, recall: 1.0000\n",
      "test_loss: 0.3708, test_acc: 0.6865, test_precision: 0.6314, test_recall: 0.8960\n",
      "epoch: 4/10\n",
      "loss: 0.1707, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.1777, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.1699, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.1622, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.1647, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.1672, acc: 1.0000, precision: 1.0000, recall: 1.0000\n",
      "loss: 0.1696, acc: 1.0000, precision: 1.0000, recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_loss_history, train_acc_history, train_precision_history, train_recall_history, \\\n",
    "    test_loss_history, test_acc_history, test_precision_history, test_recall_history = learner.fit(x_train, y_train, x_test, y_test, n_epoch, batch_size, threshold=0, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d78bb8-07e1-4b3e-92bb-d868f1d0d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i+1 for i in range(n_epoch)], train_loss_history, label=\"train_loss\")\n",
    "plt.plot([i+1 for i in range(n_epoch)], test_loss_history, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f27996-6ea4-42f4-ab18-7f1728bd1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i+1 for i in range(n_epoch)], train_acc_history, label=\"train_accuracy\")\n",
    "plt.plot([i+1 for i in range(n_epoch)], test_acc_history, label=\"test_accuracy\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e45fc-6315-44bb-8244-23e3ecd75381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i+1 for i in range(n_epoch)], train_precision_history, label=\"train_precision\")\n",
    "plt.plot([i+1 for i in range(n_epoch)], test_precision_history, label=\"test_precision\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8531f9-f330-40e9-b884-3d2819b289df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i+1 for i in range(n_epoch)], train_recall_history, label=\"train_recall\")\n",
    "plt.plot([i+1 for i in range(n_epoch)], test_recall_history, label=\"test_recall\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
